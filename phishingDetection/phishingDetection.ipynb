{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24527a3c-d227-494f-a5c7-7f3ba8c67ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.812860  [   32/ 4512]\n",
      "loss: 0.679166  [ 1472/ 4512]\n",
      "loss: 0.607368  [ 2912/ 4512]\n",
      "loss: 0.708024  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.628875 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.589325  [   32/ 4512]\n",
      "loss: 0.573288  [ 1472/ 4512]\n",
      "loss: 0.547161  [ 2912/ 4512]\n",
      "loss: 0.737168  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.618094 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.924845  [   32/ 4512]\n",
      "loss: 0.586720  [ 1472/ 4512]\n",
      "loss: 0.584918  [ 2912/ 4512]\n",
      "loss: 0.540925  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.611830 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.630540  [   32/ 4512]\n",
      "loss: 0.625181  [ 1472/ 4512]\n",
      "loss: 0.530955  [ 2912/ 4512]\n",
      "loss: 0.527722  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.607274 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.582077  [   32/ 4512]\n",
      "loss: 0.580535  [ 1472/ 4512]\n",
      "loss: 0.568918  [ 2912/ 4512]\n",
      "loss: 0.613569  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.603350 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.587109  [   32/ 4512]\n",
      "loss: 0.547658  [ 1472/ 4512]\n",
      "loss: 0.603684  [ 2912/ 4512]\n",
      "loss: 0.560605  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.599716 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.596066  [   32/ 4512]\n",
      "loss: 0.703050  [ 1472/ 4512]\n",
      "loss: 0.559857  [ 2912/ 4512]\n",
      "loss: 0.523242  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.596183 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.563629  [   32/ 4512]\n",
      "loss: 0.479125  [ 1472/ 4512]\n",
      "loss: 0.575040  [ 2912/ 4512]\n",
      "loss: 0.481745  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.592776 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.604244  [   32/ 4512]\n",
      "loss: 0.596680  [ 1472/ 4512]\n",
      "loss: 0.556931  [ 2912/ 4512]\n",
      "loss: 0.540540  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.589416 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.666493  [   32/ 4512]\n",
      "loss: 0.598944  [ 1472/ 4512]\n",
      "loss: 0.589207  [ 2912/ 4512]\n",
      "loss: 0.694324  [ 4352/ 4512]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.586115 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EmailDataset(Dataset): \n",
    "    #annotations_file - Path to .csv of email features (https://github.com/diegoocampoh/MachineLearningPhishing)\n",
    "    def __init__(self, annotations_file, train=True, transform=None):\n",
    "        self.data_frame = pd.read_csv(annotations_file)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        label = self.data_frame.iloc[index, 10]\n",
    "        row = self.data_frame.iloc[index, 0:10]\n",
    "        atInUrl =  1 if row['@ in URLs'] else 0\n",
    "        Attachments = row['Attachments']\n",
    "        Css = row['Css']\n",
    "        Ext = row['External Resources']\n",
    "        htmlcont = 1 if row['HTML content'] else 0\n",
    "        htmlform = 1 if row['Html Form'] else 0\n",
    "        htmliframe = 1 if row['Html iFrame'] else 0\n",
    "        ip = 1 if row['IPs in URLs'] else 0\n",
    "        js = row['Javascript']\n",
    "        urls = row['URLs']\n",
    "        features = [atInUrl,Attachments,Css,Ext,htmlcont,htmlform,htmliframe,ip,js,urls]\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            features_tensor = self.transform(features_tensor)\n",
    "        return features_tensor, label\n",
    "\n",
    "training_data = EmailDataset(\n",
    "    annotations_file=\"Enron-Phishing Dataset/features-enron-and-phishing.csv\",\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "test_data = EmailDataset(\n",
    "    annotations_file=\"Enron-Phishing Dataset/features-enron-and-phishing.csv\",\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 512 Nodes on 1 hidden Layer\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "learning_rate = 1e-4 #10^-3 Learning Rate\n",
    "batch_size = 32\n",
    "loss_fn = nn.CrossEntropyLoss() #Cross Entropy Loss Function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epochs = 10 #5 Runs of the dataset\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 45 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb2ca1-2615-4af4-87b6-6cb2dc11266c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
